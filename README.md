# diffusion_learning
|author|title|year|content|code|paper|
|------|----|-------|----|-----|-----|
|Jascha Sohl-Dickstein Stanford University|Deep Unsupervised Learning using Nonequilibrium Thermodynamics|2015|最早提出|https://github.com/Sohl-Dickstein/Diffusion-Probabilistic-Models|https://arxiv.org/abs/1503.03585|
|Jonathan Ho UC Berkeley|Denoising Diffusion Probabilistic Models|2020|开山之作|https://github.com/hojonathanho/diffusion|https://arxiv.org/abs/2006.11239|
|Yang Song Stanford University|Score-Based Generative Modeling through Stochastic Differential Equations|2020|数学原理|https://github.com/yang-song/score_sde|https://arxiv.org/abs/2011.13456|
|Fan Bao|Analytic-DPM: an Analytic Estimate of the Optimal Reverse Variance in Diffusion Probabilistic Models|2022|基于diffusion SDE的最快的采样方法|https://github.com/baofff/Analytic-DPM|https://arxiv.org/abs/2201.06503|
|Tero Karras|Elucidating the Design Space of Diffusion-Based Generative Models|2022|提高diffusion ODE的生成效果|https://github.com/nvlabs/edm|https://arxiv.org/abs/2206.00364|
|Vadim Popov|Diffusion-Based Voice Conversion with Fast Maximum Likelihood Sampling Scheme|2022|NA|https://github.com/huawei-noah/Speech-Backbones|https://arxiv.org/abs/2109.13821|
|Fan Bao|Estimating the Optimal Covariance with Imperfect Mean in Diffusion Probabilistic Models|2022|NA|https://github.com/baofff/Extended-Analytic-DPM|https://arxiv.org/abs/2206.07309|
|Tim Salimans|Progressive Distillation for Fast Sampling of Diffusion Models|2022|NA|https://github.com/google-research/google-research/tree/master/diffusion_distillation|https://arxiv.org/abs/2202.00512|
|Cheng Lu|DPM-Solver: A Fast ODE Solver for Diffusion Probabilistic Model Sampling in Around 10 Steps|2022|NA|https://github.com/luchengthu/dpm-solver|https://arxiv.org/abs/2206.00927|
